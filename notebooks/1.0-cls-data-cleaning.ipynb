{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('../data/raw/training_values.csv')\n",
    "train_labels = pd.read_csv('../data/raw/training_labels.csv')\n",
    "train_df = train_values.merge(train_labels, on='id')\n",
    "\n",
    "test_values = pd.read_csv('../data/raw/test_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many features have illogical values (e.g. '0' as the name of the funder).  I am replacing these illogical values with nans, as the values were likely entered as a placeholder for 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_train = train_df\n",
    "clean_test = test_values\n",
    "\n",
    "for df in [clean_train, clean_test]:\n",
    "    df['funder'].replace('0', np.nan, inplace=True)\n",
    "    df['installer'].replace('0', np.nan, inplace=True)\n",
    "    df['longitude'].replace(0, np.nan, inplace=True)\n",
    "    df['latitude'].replace(-0.00000002, np.nan, inplace=True)\n",
    "    df['population'].replace(0, np.nan, inplace=True)\n",
    "    df['construction_year'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the test features contain different conventions for capitalization (e.g. District Council vs. District council).  Thus, I am making all text values lowercase to ensure entries are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in [clean_train, clean_test]:\n",
    "    for col in df:\n",
    "        if df[col].dtype == 'O' and col not in ['permit', 'public_meeting']:\n",
    "            df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the date recorded datetime, so that alogrithms can split on before/after a certain date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train['date_recorded'] = pd.to_datetime(clean_train['date_recorded'])\n",
    "clean_test['date_recorded'] = pd.to_datetime(clean_test['date_recorded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making new column that aggregates all other text columns.  This will be passed into a naive bayes classifier to be used as a feature later on.  The goal of using this technique is to capture some of the signal held by these columns without making dummies for all of them.  Not all columns are included, as some seem to add no new information.  The recorded_by column has the same value for every entry, thus is adding no information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_train['text_cols'] = clean_train[['funder', 'installer', 'wpt_name', 'basin', 'subvillage', 'region', 'lga', 'ward', 'scheme_management', 'scheme_name', 'extraction_type', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'waterpoint_type']].values.tolist()\n",
    "clean_train.drop(['funder', 'installer', 'wpt_name', 'basin', 'subvillage', 'region', 'lga', 'ward', 'scheme_management', 'scheme_name', 'extraction_type', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'waterpoint_type', 'recorded_by', 'extraction_type_group', 'extraction_type_class', 'quantity_group', 'source_class', 'waterpoint_type_group'], axis=1, inplace=True)\n",
    "\n",
    "clean_test['text_cols'] = clean_test[['funder', 'installer', 'wpt_name', 'basin', 'subvillage', 'region', 'lga', 'ward', 'scheme_management', 'scheme_name', 'extraction_type', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'waterpoint_type']].values.tolist()\n",
    "clean_test.drop(['funder', 'installer', 'wpt_name', 'basin', 'subvillage', 'region', 'lga', 'ward', 'scheme_management', 'scheme_name', 'extraction_type', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'waterpoint_type', 'recorded_by', 'extraction_type_group', 'extraction_type_class', 'quantity_group', 'source_class', 'waterpoint_type_group'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_train['text_cols'] = clean_train['text_cols'].map(lambda x: ' '.join(x))\n",
    "clean_test['text_cols'] = clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
